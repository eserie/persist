{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dask' from '//anaconda/lib/python2.7/site-packages/dask/__init__.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function delayed at 0x104bc3938>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask import delayed\n",
    "delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "pytest.raises()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n",
      "distributed.comm.tcp - WARNING - Could not set timeout on TCP stream: [Errno 42] Protocol not available\n"
     ]
    }
   ],
   "source": [
    "from distributed import LocalCluster, Client\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('analyzed_data', 'pool1'): (<functools.partial at 0x10a550ba8>,\n",
       "  ('cleaned_data', 'pool1'),\n",
       "  1),\n",
       " ('analyzed_data', 'pool2'): (<functools.partial at 0x10ac38158>,\n",
       "  ('cleaned_data', 'pool2'),\n",
       "  1),\n",
       " ('cleaned_data', 'pool1'): (<function __main__.clean_data>,\n",
       "  ('data', 'pool1')),\n",
       " ('cleaned_data', 'pool2'): (<function __main__.clean_data>,\n",
       "  ('data', 'pool2')),\n",
       " ('data', 'pool1'): (<function __main__.load_data>,),\n",
       " ('data', 'pool2'): (<function __main__.load_data>,)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.dsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"360pt\" viewBox=\"0.00 0.00 204.12 360.00\" width=\"204pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(0.580011 0.580011) rotate(0) translate(4 616.678)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-616.678 347.923,-616.678 347.923,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- &#45;5300776722108939485 -->\n",
       "<g class=\"node\" id=\"node1\"><title>-5300776722108939485</title>\n",
       "<polygon fill=\"none\" points=\"159.385,-381.801 3.53848,-381.801 3.53848,-345.801 159.385,-345.801 159.385,-381.801\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.4615\" y=\"-359.601\">('cleaned_data', 'pool2')</text>\n",
       "</g>\n",
       "<!-- 2410200536988902493 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2410200536988902493</title>\n",
       "<ellipse cx=\"81.4615\" cy=\"-479.239\" fill=\"none\" rx=\"61.3761\" ry=\"61.3761\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.4615\" y=\"-475.039\">analyze_data</text>\n",
       "</g>\n",
       "<!-- &#45;5300776722108939485&#45;&gt;2410200536988902493 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>-5300776722108939485-&gt;2410200536988902493</title>\n",
       "<path d=\"M81.4615,-382.03C81.4615,-389.252 81.4615,-398.17 81.4615,-407.638\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.9616,-407.656 81.4615,-417.656 84.9616,-407.656 77.9616,-407.656\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2538146433059717352 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2538146433059717352</title>\n",
       "<ellipse cx=\"81.4615\" cy=\"-257.479\" fill=\"none\" rx=\"52.1463\" ry=\"52.1463\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.4615\" y=\"-253.279\">clean_data</text>\n",
       "</g>\n",
       "<!-- 2538146433059717352&#45;&gt;&#45;5300776722108939485 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2538146433059717352-&gt;-5300776722108939485</title>\n",
       "<path d=\"M81.4615,-310.029C81.4615,-318.682 81.4615,-327.357 81.4615,-335.102\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.9616,-335.333 81.4615,-345.333 84.9616,-335.333 77.9616,-335.333\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5200419663265502364 -->\n",
       "<g class=\"node\" id=\"node3\"><title>5200419663265502364</title>\n",
       "<polygon fill=\"none\" points=\"134.636,-169.156 28.2874,-169.156 28.2874,-133.156 134.636,-133.156 134.636,-169.156\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.4615\" y=\"-146.956\">('data', 'pool2')</text>\n",
       "</g>\n",
       "<!-- 5200419663265502364&#45;&gt;2538146433059717352 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>5200419663265502364-&gt;2538146433059717352</title>\n",
       "<path d=\"M81.4615,-169.383C81.4615,-176.608 81.4615,-185.487 81.4615,-194.786\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.9616,-194.981 81.4615,-204.981 84.9616,-194.981 77.9616,-194.981\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- &#45;1443455424474306218 -->\n",
       "<g class=\"node\" id=\"node4\"><title>-1443455424474306218</title>\n",
       "<polygon fill=\"none\" points=\"162.885,-612.678 0.0384818,-612.678 0.0384818,-576.678 162.885,-576.678 162.885,-612.678\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.4615\" y=\"-590.478\">('analyzed_data', 'pool2')</text>\n",
       "</g>\n",
       "<!-- 2410200536988902493&#45;&gt;&#45;1443455424474306218 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2410200536988902493-&gt;-1443455424474306218</title>\n",
       "<path d=\"M81.4615,-540.944C81.4615,-549.823 81.4615,-558.572 81.4615,-566.313\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.9616,-566.495 81.4615,-576.495 84.9616,-566.495 77.9616,-566.495\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5200419663266584889 -->\n",
       "<g class=\"node\" id=\"node6\"><title>5200419663266584889</title>\n",
       "<polygon fill=\"none\" points=\"315.636,-169.156 209.287,-169.156 209.287,-133.156 315.636,-133.156 315.636,-169.156\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.462\" y=\"-146.956\">('data', 'pool1')</text>\n",
       "</g>\n",
       "<!-- 8835412057947564777 -->\n",
       "<g class=\"node\" id=\"node9\"><title>8835412057947564777</title>\n",
       "<ellipse cx=\"262.462\" cy=\"-257.479\" fill=\"none\" rx=\"52.1463\" ry=\"52.1463\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.462\" y=\"-253.279\">clean_data</text>\n",
       "</g>\n",
       "<!-- 5200419663266584889&#45;&gt;8835412057947564777 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>5200419663266584889-&gt;8835412057947564777</title>\n",
       "<path d=\"M262.462,-169.383C262.462,-176.608 262.462,-185.487 262.462,-194.786\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258.962,-194.981 262.462,-204.981 265.962,-194.981 258.962,-194.981\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1467703301102581010 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1467703301102581010</title>\n",
       "<ellipse cx=\"262.462\" cy=\"-48.5779\" fill=\"none\" rx=\"48.6559\" ry=\"48.6559\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.462\" y=\"-44.3779\">load_data</text>\n",
       "</g>\n",
       "<!-- 1467703301102581010&#45;&gt;5200419663266584889 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1467703301102581010-&gt;5200419663266584889</title>\n",
       "<path d=\"M262.462,-97.216C262.462,-106.013 262.462,-114.918 262.462,-122.851\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258.962,-122.964 262.462,-132.964 265.962,-122.964 258.962,-122.964\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- &#45;5300776722105691910 -->\n",
       "<g class=\"node\" id=\"node8\"><title>-5300776722105691910</title>\n",
       "<polygon fill=\"none\" points=\"340.385,-381.801 184.538,-381.801 184.538,-345.801 340.385,-345.801 340.385,-381.801\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.462\" y=\"-359.601\">('cleaned_data', 'pool1')</text>\n",
       "</g>\n",
       "<!-- 4308161845663928668 -->\n",
       "<g class=\"node\" id=\"node12\"><title>4308161845663928668</title>\n",
       "<ellipse cx=\"262.462\" cy=\"-479.239\" fill=\"none\" rx=\"61.3761\" ry=\"61.3761\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.462\" y=\"-475.039\">analyze_data</text>\n",
       "</g>\n",
       "<!-- &#45;5300776722105691910&#45;&gt;4308161845663928668 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>-5300776722105691910-&gt;4308161845663928668</title>\n",
       "<path d=\"M262.462,-382.03C262.462,-389.252 262.462,-398.17 262.462,-407.638\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258.962,-407.656 262.462,-417.656 265.962,-407.656 258.962,-407.656\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 8835412057947564777&#45;&gt;&#45;5300776722105691910 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>8835412057947564777-&gt;-5300776722105691910</title>\n",
       "<path d=\"M262.462,-310.029C262.462,-318.682 262.462,-327.357 262.462,-335.102\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258.962,-335.333 262.462,-345.333 265.962,-335.333 258.962,-335.333\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1229595320426462135 -->\n",
       "<g class=\"node\" id=\"node10\"><title>1229595320426462135</title>\n",
       "<ellipse cx=\"81.4615\" cy=\"-48.5779\" fill=\"none\" rx=\"48.6559\" ry=\"48.6559\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.4615\" y=\"-44.3779\">load_data</text>\n",
       "</g>\n",
       "<!-- 1229595320426462135&#45;&gt;5200419663265502364 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>1229595320426462135-&gt;5200419663265502364</title>\n",
       "<path d=\"M81.4615,-97.216C81.4615,-106.013 81.4615,-114.918 81.4615,-122.851\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"77.9616,-122.964 81.4615,-132.964 84.9616,-122.964 77.9616,-122.964\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- &#45;1443455424477553793 -->\n",
       "<g class=\"node\" id=\"node11\"><title>-1443455424477553793</title>\n",
       "<polygon fill=\"none\" points=\"343.885,-612.678 181.038,-612.678 181.038,-576.678 343.885,-576.678 343.885,-612.678\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262.462\" y=\"-590.478\">('analyzed_data', 'pool1')</text>\n",
       "</g>\n",
       "<!-- 4308161845663928668&#45;&gt;&#45;1443455424477553793 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>4308161845663928668-&gt;-1443455424477553793</title>\n",
       "<path d=\"M262.462,-540.944C262.462,-549.823 262.462,-558.572 262.462,-566.313\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"258.962,-566.495 262.462,-576.495 265.962,-566.495 258.962,-566.495\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask import visualize\n",
    "visualize(g.dsk, format='svg', size=\"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Exception in callback <functools.partial object at 0x10ad80940>\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/tornado/ioloop.py\", line 600, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"//anaconda/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"//anaconda/lib/python2.7/site-packages/distributed/batched.py\", line 98, in send\n",
      "    raise CommClosedError\n",
      "CommClosedError\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-dd2ffc9c1949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;34m'analyzed_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/distributed/client.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         return sync(self.loop, self._get, dsk, keys, restrictions=restrictions,\n\u001b[1;32m   1524\u001b[0m                     \u001b[0mloose_restrictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloose_restrictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m                     resources=resources)\n\u001b[0m\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize_insert_futures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/distributed/utils.pyc\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0m_sleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgotit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client.get(g.dsk,  ('analyzed_data', 'pool2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data ...\n",
      "save data with key ('data', 'pool1') ...\n",
      "clean data ...\n",
      "save data with key ('cleaned_data', 'pool1') ...\n",
      "analyze data ...\n",
      "save data with key ('analyzed_data', 'pool1') ...\n",
      "data= analyzed_data\n",
      "Checking that it is cached\n",
      "data= analyzed_data\n",
      "data= cleaned_data\n",
      "\n",
      "load data ...\n",
      "save data with key ('data', 'pool2') ...\n",
      "clean data ...\n",
      "save data with key ('cleaned_data', 'pool2') ...\n",
      "data= cleaned_data\n",
      "\n",
      "analyze data ...\n",
      "save data with key ('analyzed_data', 'pool2') ...\n",
      "data= analyzed_data\n",
      "\n",
      "get multiple results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('analyzed_data', 'pool1'): 'analyzed_data',\n",
       " ('analyzed_data', 'pool2'): 'analyzed_data'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global variable to simulate the fact to have serialize data somewhere\n",
    "IS_COMPUTED = dict()\n",
    "\n",
    "from functools import partial\n",
    "from dask import get\n",
    "from dask.optimize import cull\n",
    "from functools import wraps\n",
    "import inspect\n",
    "        \n",
    "def load_data():\n",
    "    print 'load data ...'\n",
    "    return 'data'\n",
    "\n",
    "def clean_data(data):\n",
    "    assert isinstance(data, str)\n",
    "    print 'clean data ...'\n",
    "    return 'cleaned_data'\n",
    "\n",
    "def analyze_data(cleaned_data, option=1, **other_options):\n",
    "    assert isinstance(cleaned_data, str)\n",
    "    print 'analyze data ...'\n",
    "    return 'analyzed_data'\n",
    "\n",
    "class Serializer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load(self, key):\n",
    "        print \"load data for key {} ...\".format(key)\n",
    "        return key\n",
    "    \n",
    "    def dump(self, key, value):\n",
    "        print \"save data with key {} ...\".format(key)\n",
    "        IS_COMPUTED[key] = True\n",
    "        \n",
    "    def is_computed(self, key):\n",
    "        return IS_COMPUTED.get(key)\n",
    "    \n",
    "    def delayed_load(self, key):\n",
    "        def load():\n",
    "            return self.load(key)\n",
    "        return load\n",
    "    \n",
    "    def dump_result(self, func, key):\n",
    "        @wraps(func)\n",
    "        def wrapped_func(*args, **kwargs):\n",
    "            result =  func(*args, **kwargs)\n",
    "            self.dump(key, result)\n",
    "            return result\n",
    "        return wrapped_func\n",
    "\n",
    "\n",
    "class Graph(object):\n",
    "    def __init__(self):\n",
    "        self.dsk = dict()\n",
    "        self.cache = dict()\n",
    "        self.serializer = dict()\n",
    "        \n",
    "    def add_task(self, key, serializer, func, *args, **kwargs):\n",
    "        self.serializer[key] = serializer\n",
    "        # prepare arguments for the dask graph specification\n",
    "        args_dict = inspect.getcallargs(func, *args, **kwargs)\n",
    "        args_spec = inspect.getargspec(func)\n",
    "        args_list = [args_dict[argname] for argname in args_spec.args]\n",
    "        # dump data as side effect\n",
    "        func = serializer.dump_result(func, key)\n",
    "        # propagate keyword arguments\n",
    "        if args_spec.keywords:\n",
    "            func = partial(func, **args_dict[args_spec.keywords])\n",
    "        # add task to dask graph\n",
    "        self.dsk[key] = (func,) + tuple(args_list)\n",
    "        return key\n",
    "        \n",
    "    @property\n",
    "    def persistent_dsk(self):\n",
    "        dsk = self.dsk.copy()\n",
    "        # load instead of compute\n",
    "        # the fact to call the method \"is_computed\" may slow down the code.\n",
    "        dsk.update({key : (self.serializer[key].delayed_load(key),) for key in dsk.keys() if key in self.serializer and self.serializer[key].is_computed(key)})\n",
    "        #Use cache instead of loadind\n",
    "        dsk.update({key : self.cache[key] for key in dsk.keys() if key in self.cache})\n",
    "        return dsk\n",
    "        \n",
    "    def run(self, key=None):\n",
    "        if key is None:\n",
    "            key = self.dsk.keys()\n",
    "        dsk = self.persistent_dsk\n",
    "        dsk, _ = cull(dsk, key)\n",
    "        # get all necessary results\n",
    "        keys = dsk.keys()\n",
    "        results = dict(zip(keys, get(dsk, keys)))\n",
    "        # store in cache\n",
    "        self.cache.update(results)\n",
    "        \n",
    "    def get(self, key):\n",
    "        self.run(key)\n",
    "        try:\n",
    "            return self.cache[key]\n",
    "        except (TypeError, KeyError):\n",
    "            return {k : self.cache[k] for k in key}\n",
    "    \n",
    "\n",
    "def setup_graph():\n",
    "    g = Graph()\n",
    "    serializer = Serializer()\n",
    "    for pool in ['pool1', 'pool2']:\n",
    "        g.add_task(('data', pool), serializer, load_data)\n",
    "        g.add_task(('cleaned_data', pool), serializer, clean_data, ('data', pool) )\n",
    "        g.add_task(('analyzed_data', pool), serializer, analyze_data, ('cleaned_data', pool))\n",
    "    return g\n",
    "\n",
    "g = setup_graph()\n",
    "data = g.get(('analyzed_data', 'pool1'))\n",
    "print \"data=\", data\n",
    "print \"Checking that it is cached\"\n",
    "data = g.get(('analyzed_data', 'pool1'))\n",
    "print \"data=\", data\n",
    "data = g.get(('cleaned_data', 'pool1'))\n",
    "print \"data=\", data\n",
    "print \"\"\n",
    "\n",
    "\n",
    "data = g.get(('cleaned_data', 'pool2'))\n",
    "print \"data=\", data\n",
    "print \"\"\n",
    "\n",
    "\n",
    "data = g.get(('analyzed_data', 'pool2'))\n",
    "print \"data=\", data\n",
    "print \"\"\n",
    "\n",
    "print \"get multiple results\"\n",
    "g.get([('analyzed_data', 'pool1'), ('analyzed_data', 'pool2')])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "func = analyze_data\n",
    "\n",
    "args_dict = inspect.getcallargs(func, \"toto\", 2, test=True)\n",
    "args_spec = inspect.getargspec(func)\n",
    "args_list = [args_dict[argname] for argname in args_spec.args]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('analyzed_data', 'pool1'): (<functools.partial object at 0x10acc4730>,\n",
      "                              ('cleaned_data', 'pool1'),\n",
      "                              1),\n",
      " ('analyzed_data', 'pool2'): (<functools.partial object at 0x10adb3368>,\n",
      "                              ('cleaned_data', 'pool2'),\n",
      "                              1),\n",
      " ('cleaned_data', 'pool1'): (<function clean_data at 0x10ac407d0>,\n",
      "                             ('data', 'pool1')),\n",
      " ('cleaned_data', 'pool2'): (<function clean_data at 0x10a56f0c8>,\n",
      "                             ('data', 'pool2')),\n",
      " ('data', 'pool1'): (<function load_data at 0x10ac408c0>,),\n",
      " ('data', 'pool2'): (<function load_data at 0x10a56f668>,)}\n",
      "load data ...\n",
      "save data with key ('data', 'pool1') ...\n",
      "clean data ...\n",
      "save data with key ('cleaned_data', 'pool1') ...\n",
      "analyze data ...\n",
      "save data with key ('analyzed_data', 'pool1') ...\n",
      "load data ...\n",
      "save data with key ('data', 'pool2') ...\n",
      "clean data ...\n",
      "save data with key ('cleaned_data', 'pool2') ...\n",
      "analyze data ...\n",
      "save data with key ('analyzed_data', 'pool2') ...\n",
      "{('analyzed_data', 'pool1'): 'analyzed_data',\n",
      " ('analyzed_data', 'pool2'): 'analyzed_data',\n",
      " ('cleaned_data', 'pool1'): 'cleaned_data',\n",
      " ('cleaned_data', 'pool2'): 'cleaned_data',\n",
      " ('data', 'pool1'): 'data',\n",
      " ('data', 'pool2'): 'data'}\n",
      "{('analyzed_data', 'pool1'): (<function load at 0x10ad542a8>,),\n",
      " ('analyzed_data', 'pool2'): (<function load at 0x10a56fcf8>,),\n",
      " ('cleaned_data', 'pool1'): (<function load at 0x10a56f0c8>,),\n",
      " ('cleaned_data', 'pool2'): (<function load at 0x10ac408c0>,),\n",
      " ('data', 'pool1'): (<function load at 0x10a56f668>,),\n",
      " ('data', 'pool2'): (<function load at 0x10ad54cf8>,)}\n",
      "get multiple results\n",
      "load data for key ('analyzed_data', 'pool1') ...\n",
      "load data for key ('analyzed_data', 'pool2') ...\n",
      "data= {('analyzed_data', 'pool2'): ('analyzed_data', 'pool2'), ('analyzed_data', 'pool1'): ('analyzed_data', 'pool1')}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "IS_COMPUTED = dict()\n",
    "g = setup_graph()\n",
    "# the first time the grap is created it has functions\n",
    "pprint(g.persistent_dsk)\n",
    "# run the graph\n",
    "g.run()\n",
    "# then the graph is replaced by cached data\n",
    "pprint(g.persistent_dsk)\n",
    "\n",
    "# If we recreate a new graph (the cache is delete)\n",
    "g = setup_graph()\n",
    "# the graph conainte the load methods\n",
    "pprint(g.persistent_dsk)\n",
    "\n",
    "\n",
    "print \"get multiple results\"\n",
    "data = g.get([('analyzed_data', 'pool1'), ('analyzed_data', 'pool2')])\n",
    "print \"data=\", data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.base.Base at 0x10ad67d10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.base import Base\n",
    "Base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got NoneType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-24ebb0f079fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mBag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'analyzed_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mExtra\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0mto\u001b[0m \u001b[0mforward\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \"\"\"\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                              \"the `get` kwarg or globally with `set_options`.\")\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections_to_dsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36mcollections_to_dsk\u001b[0;34m(collections, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         groups = {opt: _extract_graph_and_keys(val)\n\u001b[0;32m--> 427\u001b[0;31m                   for opt, val in groups.items()}\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             groups = {k: [opt(ensure_dict(dsk), keys), keys]\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((opt, val))\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         groups = {opt: _extract_graph_and_keys(val)\n\u001b[0;32m--> 427\u001b[0;31m                   for opt, val in groups.items()}\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             groups = {k: [opt(ensure_dict(dsk), keys), keys]\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/dask/base.pyc\u001b[0m in \u001b[0;36m_extract_graph_and_keys\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mdsk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/dask/bag/core.pyc\u001b[0m in \u001b[0;36m_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range() integer end argument expected, got NoneType."
     ]
    }
   ],
   "source": [
    "from dask.bag import Bag\n",
    "b =Bag(g.dsk, ('analyzed_data', 'pool2'), None)\n",
    "b.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
